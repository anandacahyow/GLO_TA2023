{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM System Identification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Ananda Cahyo Wibowo<br />\n",
    "NRP : 07111940000128 <br />\n",
    "Undergrad Thesis Title : Data Driven Gas Lift Well And Network Optimization With Neural Network Based System Identification Using Modbus Simulator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "#from datetime import datetime\n",
    "\n",
    "#Read the csv file\n",
    "df = pd.read_csv(\"upsample_min.csv\")\n",
    "df = pd.read_csv(\"upsample.csv\")\n",
    "df = pd.read_csv(\"upsampled_matlab_nonrevised.csv\")\n",
    "#df = pd.read_csv(\"upsampled_matlab.csv\")\n",
    "df = pd.read_csv(\"upsampled_matlab_rev.csv\")\n",
    "#df = pd.read_csv(\"upsampled_matlab_lama.csv\")\n",
    "df2=df.drop(df.columns[0], axis=1)\n",
    "data = df['glir11'].to_numpy()\n",
    "\n",
    "split = 0.75\n",
    "epoch = 15\n",
    "batchsize = 15\n",
    "filename = \"RNN_type3_\" + f\"{epoch}+{batchsize}\" \n",
    "\n",
    "x1 = df['glir11'].to_numpy()[:int(split*len(data))]\n",
    "x1 = x1.reshape(len(x1),1)\n",
    "y1 = df['qt11'].to_numpy()[:int(split*len(data))]\n",
    "y1 = y1.reshape(len(y1),1)\n",
    "\n",
    "x2 = df['glir11'].to_numpy()[int(split*len(data)):]\n",
    "y2 = df['qt11'].to_numpy()[int(split*len(data)):]\n",
    "\n",
    "print(f\"ukuran x train: {np.shape(x1)} ukuran y train: {np.shape(y1)}\")\n",
    "print(f\"ukuran x test: {np.shape(x2)} ukuran y test: {np.shape(y2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,len(y2)),y2)\n",
    "plt.plot(np.arange(0,len(y2)),x2*0.2)\n",
    "plt.grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New dataframe with only training data\n",
    "df_for_training_x = x1\n",
    "df_for_training_y = y1\n",
    "\n",
    "#LSTM uses sigmoid and tanh that are sensitive to magnitude so values need to be normalized\n",
    "# normalize the dataset\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(df_for_training_x)\n",
    "scaler2 = scaler.fit(df_for_training_y)\n",
    "df_for_training_scaled_x = scaler.transform(df_for_training_x)\n",
    "df_for_training_scaled_y = scaler2.transform(df_for_training_y)\n",
    "\n",
    "#As required for LSTM networks, we require to reshape an input data into n_samples x timesteps x n_features. \n",
    "#In this example, the n_features is 5. We will make timesteps = 14 (past days data used for training). \n",
    "\n",
    "#Empty lists to be populated using formatted training data\n",
    "trainX = []\n",
    "trainY = []\n",
    "\n",
    "n_future = 1   # Number of days we want to look into the future based on the past days.\n",
    "n_past = 14  # Number of past days we want to use to predict the future.\n",
    "\n",
    "#Reformat input data into a shape: (n_samples x timesteps x n_features)\n",
    "#In my example, my df_for_training_scaled has a shape (12823, 5)\n",
    "#12823 refers to the number of data points and 5 refers to the columns (multi-variables).\n",
    "for i in range(n_past, len(df_for_training_scaled_x) - n_future +1):\n",
    "    trainX.append(df_for_training_scaled_x[i - n_past:i, 0:df_for_training_x.shape[1]])\n",
    "\n",
    "for i in range(n_past, len(df_for_training_scaled_y) - n_future +1):\n",
    "    trainY.append(df_for_training_scaled_y[i + n_future - 1:i + n_future, 0])\n",
    "\n",
    "trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "\n",
    "print('trainX shape == {}.'.format(trainX.shape))\n",
    "print('trainY shape == {}.'.format(trainY.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN LSTM Architecture & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Autoencoder model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(64, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(32, activation='relu', return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(trainY.shape[1]))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "history = model.fit(trainX, trainY, epochs=epoch, batch_size=batchsize, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"RNN_TFORDE1\")\n",
    "#model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.models import load_model\n",
    "#model = load_model(\"RNN_model_resolved\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights and Biasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [0,1,2,4] #layer 0:lstm 1:lstm 3:dense\n",
    "\n",
    "weights = {}\n",
    "biases = {}\n",
    "for layer in layers:\n",
    "    weights[layer] = model.layers[layer].get_weights()[0]\n",
    "    biases[layer] = model.layers[layer].get_weights()[1]\n",
    "\n",
    "nlayer = 1\n",
    "print(np.shape(weights[nlayer]))\n",
    "print(weights[nlayer])\n",
    "\n",
    "print(np.shape(biases[nlayer]))\n",
    "print(biases[nlayer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.arange(0,len(history.history['loss']))\n",
    "\n",
    "\"\"\"print(history.history['loss'])\n",
    "print(history.history['val_loss'])\n",
    "print(xx)\"\"\"\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(xx,history.history['loss'], label='Training loss')\n",
    "plt.plot(xx,history.history['val_loss'], label='Validation loss')\n",
    "plt.title(\"Training Loss vs Validation Loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"val\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make prediction\n",
    "#model = keras.models.load_model(\"RNN_Model\")\n",
    "\n",
    "n_days_for_prediction = 20\n",
    "prediction = model.predict(trainX[:]) #shape = (n, 1) where n is the n_days_for_prediction\n",
    "\n",
    "#Perform inverse transformation to rescale back to original range\n",
    "\n",
    "prediction_copies = np.repeat(prediction, df_for_training_y.shape[1], axis=-1)\n",
    "y_pred_future = scaler.inverse_transform(prediction_copies)\n",
    "\n",
    "print('nilai pred:',y_pred_future)\n",
    "\n",
    "yy = scaler.inverse_transform(trainY)\n",
    "\n",
    "x_axis = np.arange(0,y_pred_future.shape[0])\n",
    "\n",
    "print(f\"ukuran y: {np.shape(yy)} ukuran y pred: {np.shape(y_pred_future)}\")\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(x_axis,y_pred_future, label='pred')\n",
    "plt.plot(x_axis,yy, label='well test')\n",
    "plt.title(\"Comparison of TRAIN DATA: Well Production Data and LSTM Network\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"Oil Flow Rate Production (STB/day)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "MSE = np.square(np.subtract(yy,y_pred_future)).mean() \n",
    " \n",
    "RMSE = math.sqrt(MSE)\n",
    "print(\"Root Mean Square Error:\")\n",
    "print(round(RMSE,2))\n",
    "\n",
    "r2 = r2_score(yy,y_pred_future)\n",
    "print(\"\\nR2 Value:\")\n",
    "print(round(r2,2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting Value/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "#model = load_model(\"RNN_model_resolved_bagus_0.6r1\") #BAGUSSSSSS\n",
    "#model = load_model(\"RNN_model_resolved100\")\n",
    "model = load_model(\"RNN_TFORDE1\")\n",
    "#df2 = pd.read_csv(\"upsample.csv\")\n",
    "#df2 = df2.iloc[:,0:152]\n",
    "x2 = df['glir11'].to_numpy()[int(split*len(data)):]\n",
    "y2 = df['qt11'].to_numpy()[int(split*len(data)):]\n",
    "\n",
    "#x2 = df2['glir11'].to_numpy()\n",
    "#y2 = df2['qt11'].to_numpy()\n",
    "\n",
    "#New dataframe with only testing data\n",
    "x2 = x2.reshape(len(x2),1)\n",
    "y2 = y2.reshape(len(y2),1)\n",
    "df_for_testing_x = x2\n",
    "df_for_testing_y = y2\n",
    "\n",
    "#LSTM uses sigmoid and tanh that are sensitive to magnitude so values need to be normalized\n",
    "# normalize the dataset\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(df_for_testing_x)\n",
    "scaler2 = scaler.fit(df_for_testing_y)\n",
    "\n",
    "df_for_testing_scaled_x = scaler.transform(df_for_testing_x)\n",
    "df_for_testing_scaled_y = scaler2.transform(df_for_testing_y)\n",
    "\n",
    "#As required for LSTM networks, we require to reshape an input data into n_samples x timesteps x n_features. \n",
    "#In this example, the n_features is 5. We will make timesteps = 14 (past days data used for testing). \n",
    "\n",
    "#Empty lists to be populated using formatted testing data\n",
    "testX = []\n",
    "testY = []\n",
    "\n",
    "n_future = 1   # Number of days we want to look into the future based on the past days.\n",
    "n_past = 14  # Number of past days we want to use to predict the future.\n",
    "\n",
    "#Reformat input data into a shape: (n_samples x timesteps x n_features)\n",
    "#In my example, my df_for_testing_scaled has a shape (12823, 5)\n",
    "#12823 refers to the number of data points and 5 refers to the columns (multi-variables).\n",
    "for i in range(n_past, len(df_for_testing_scaled_x) - n_future +1):\n",
    "    testX.append(df_for_testing_scaled_x[i - n_past:i, 0:df_for_testing_x.shape[1]])\n",
    "\n",
    "for i in range(n_past, len(df_for_testing_scaled_y) - n_future +1):\n",
    "    testY.append(df_for_testing_scaled_y[i + n_future - 1:i + n_future, 0])\n",
    "\n",
    "testX, testY = np.array(testX), np.array(testY)\n",
    "\n",
    "print('testX shape == {}.'.format(testX.shape))\n",
    "print('testY shape == {}.'.format(testY.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make forecast\n",
    "#model = keras.models.load_model(\"RNN_Model\")\n",
    "\n",
    "n_days_for_forecast = 20\n",
    "forecast = model.predict(testX[:]) #shape = (n, 1) where n is the n_days_for_forecast\n",
    "\n",
    "#Perform inverse transformation to rescale back to original range\n",
    "\n",
    "forecast_copies = np.repeat(forecast, df_for_testing_y.shape[1], axis=-1)\n",
    "y_fore_future = scaler.inverse_transform(forecast_copies)\n",
    "\n",
    "#print('nilai pred:',y_fore_future)\n",
    "\n",
    "yyy = scaler.inverse_transform(testY[:])\n",
    "\n",
    "x_axis = np.arange(0,y_fore_future.shape[0])\n",
    "\n",
    "print(f\"ukuran y: {np.shape(yyy)} ukuran y pred: {np.shape(y_fore_future)}\")\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(x_axis,y_fore_future, label='pred')\n",
    "plt.plot(x_axis,yyy, label='well test')\n",
    "plt.title(\"Comparison of TEST DATA: Well Production Data and LSTM Network\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"Oil Flow Rate Production (STB/day)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "MSE = np.square(np.subtract(yyy,y_fore_future)).mean() \n",
    " \n",
    "RMSE = math.sqrt(MSE)\n",
    "print(\"Root Mean Square Error:\")\n",
    "print(round(RMSE,2))\n",
    "\n",
    "r2 = r2_score(yyy,y_fore_future)\n",
    "print(\"\\nR2 Value:\")\n",
    "print(round(r2,2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test in the looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "#model = load_model(\"RNN_model_resolved100\")\n",
    "input = []\n",
    "output = []\n",
    "i = 0\n",
    "n_past = 14\n",
    "input_init = []\n",
    "forecasting = []\n",
    "while True:\n",
    "    if i < n_past:\n",
    "        ran = random.randint(600,2000)\n",
    "        input_init.append(ran)\n",
    "        input_zero = np.zeros((n_past-(i+1),))\n",
    "        input_zero = input_zero.tolist()\n",
    "\n",
    "        input_totall = input_init + input_zero\n",
    "        print('VALUES',input_totall,'type',np.shape(input_totall))\n",
    "        input_total = np.array(input_totall)\n",
    "        input_total = np.reshape(input_total,(1,n_past,1))\n",
    "\n",
    "        forecastt = model.predict(input_total) #shape = (n, 1) where n is the n_days_for_forecast\n",
    "        forecastt = forecastt.tolist()[0][0]\n",
    "        forecasting.append(forecastt)\n",
    "\n",
    "        fig, ax_left = plt.subplots()\n",
    "        ax_left.plot(list(range(len(forecasting))),forecasting,'-go', label = 'well pred')\n",
    "        ax_left.set_ylabel('well pred')\n",
    "\n",
    "        ax_right = ax_left.twinx()\n",
    "        ax_right.plot(list(range(len(input_total[0,:,:]))),input_total[0,:,:], label = 'glir')\n",
    "        ax_right.set_ylabel('glir')\n",
    "        ax_left.legend()\n",
    "        ax_right.legend()\n",
    "        ax_left.grid()\n",
    "        \n",
    "        plt.pause(0.05)\n",
    "        fig.clear()\n",
    "\n",
    "        input_total = input_init + input_zero\n",
    "        i+=1\n",
    "    else:\n",
    "        ran = random.randint(600,2000)\n",
    "        input_totall.append(ran)\n",
    "        print('VALUES',input_totall,'type',np.shape(input_totall))\n",
    "        input_total = input_totall[-n_past:]\n",
    "        input_total = np.array(input_total)\n",
    "        input_total = np.reshape(input_total,(1,n_past,1))\n",
    "        print('VALUE',input_total,'type',np.shape(input_total))\n",
    "\n",
    "        forecastt = model.predict(input_total) #shape = (n, 1) where n is the n_days_for_forecast\n",
    "        forecastt = forecastt.tolist()[0][0]\n",
    "        forecasting.append(forecastt)\n",
    "\n",
    "        #print(\"done\")\n",
    "        #print('forecasted:',forecasting)\n",
    "        fig, ax_left = plt.subplots()\n",
    "        ax_left.plot(list(range(len(forecasting))),forecasting,'-go', label = 'well pred')\n",
    "        ax_left.set_ylabel('well pred')\n",
    "\n",
    "        ax_right = ax_left.twinx()\n",
    "        ax_right.plot(list(range(len(input_totall[:]))),input_totall[:], label = 'glir')\n",
    "        ax_right.set_ylabel('glir') \n",
    "        ax_left.legend()\n",
    "        ax_right.legend()\n",
    "        ax_left.grid()\n",
    "        \n",
    "        plt.pause(0.05)\n",
    "        fig.clear()\n",
    "        i+=1\n",
    "        #break\n",
    "    #plt.show()\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14958d3aee5f1cad06795f787e54b96185c25fb40dfec723a5be941f3a531b8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
